---
title: "Master Thesis"
weight: 5
# aliases: ["/first"]
author: ["Francesco Ortu" ] # multiple authors
# author: ["Me", "You"] # multiple authors
date: 2024-03-20T19:33:35-08:00
showToc: false
TocOpen: false
draft: false
hidemeta: false
comments: false
canonicalURL: "/publications/"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: true
searchHidden: true
ShowReadingTime: false
ShowBreadCrumbs: false
ShowPostNavLinks: false
ShowWordCount: false
ShowRssButtonInSectionTermList: false
UseHugoToc: true
cover:
    image: "<image path/url>" # image path/url
    alt: "<alt text>" # alt text
    caption: "<text>" # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
---

[![Master Thessis](https://img.shields.io/badge/Download%20Here-8A2BE2)](https://drive.google.com/file/d/1bWY1Tl5pvMpzm2TDEQ453HJCI5C9fH0U/view?usp=sharing)
## Abstract
L’introduzione dei Modelli di Linguaggio di Grande Dimensione (LLMs) ha rappresentato una rivoluzione nell’elaborazione del linguaggio naturale e nel modo in cui gli esseri umani interagiscono con le macchine. In particolare, la serie GPT di OpenAI si è distinta per la sua notevole capacità di comprendere e generare testi in modo simile a quello umano, guadagnando rapidamente un’ampia base di utenti grazie alla sua applicabilità in campi come il dialogo o la scrittura e grazie alle sorprendenti abilità di ragionamento dimostrate. Nonostante le loro prestazioni straordinarie, questi modelli, similmente ad altri sistemi di intelligenza artificiale basati su reti neurali, presentano la complessa sfida di decifrare i meccanismi interni che ne regolano il funzionamento e il modo in cui le informazioni vengono rappresentate internamente. Una profonda comprensione di tali aspetti è cruciale per migliorare le prestazioni e garantire la sicurezza dei LLMs. Questa tesi esplora dal punto di vista meccanicistico l’interazione tra i meccanismi decisionali negli LLMs, ponendo l’accento sulla relazione tra
il recupero di informazioni fattuali e la tendenza a ricopiare informazioni fornite all’interno degli input. In particolare, la ricerca si focalizza sull’analisi dell’interazione tra questi meccanismi e sull’identificazione delle componenti chiave dei modelli che influenzano questa dinamica competitiva. Viene inoltre dimostrato che, acquisendo una comprensione, seppur parziale e limitata, del funzionamento interno degli LLMs, è possibile indirizzare la generazione di testo verso risultati specifici.


